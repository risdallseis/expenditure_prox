{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import seaborn as sns\r\n",
    "from sklearn.cluster import KMeans\r\n",
    "from sklearn.metrics import adjusted_rand_score\r\n",
    "from sklearn.cluster import DBSCAN\r\n",
    "from numpy import unique, where\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "import os\r\n",
    "os.chdir('../../')\r\n",
    "\r\n",
    "from modules import preproc\r\n",
    "from modules.join_data import join_y\r\n",
    "from modules import feature_eng\r\n",
    "from modules import cluster_intelligence\r\n",
    "from modules.evaluate_model import get_eval_scores\r\n",
    "from modules.dbscan_grid_search import run_dbscan_gs\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings(\"ignore\")\r\n",
    "pd.set_option('display.max_rows',150)\r\n",
    "pd.set_option('display.max_columns',1000)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'evaluate_model'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-259c8b71875f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmodules\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcluster_intelligence\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_eval_scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdbscan_grid_search\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrun_dbscan_gs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Rory\\Desktop\\projects\\expenditure_prox\\modules\\dbscan_grid_search.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDBSCAN\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mevaluate_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_eval_scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'evaluate_model'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(os.getcwd())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reading in data and preproc"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# laptops\r\n",
    "laptops = pd.read_json('full_data/laptops.json')\r\n",
    "laptops = join_y(laptops, 'raw_data/laptops_sales.csv')\r\n",
    "laptops = preproc.clean_cols(laptops)\r\n",
    "laptops = preproc.fill_empty_lists(laptops)\r\n",
    "laptops = preproc.preprocess_reviews(laptops)\r\n",
    "laptops = feature_eng.generate_features(laptops)\r\n",
    "laptops = feature_eng.do_PCA(laptops)\r\n",
    "laptops['TOTAL_SALES_QBINNED'] = pd.qcut(laptops['TOTAL_SALES'], 3, labels=[0,1,2])\r\n",
    "\r\n",
    "# phones\r\n",
    "phones = pd.read_json('full_data/smartphones.json')\r\n",
    "phones = join_y(phones, 'raw_data/phone_sales.csv')\r\n",
    "phones = preproc.clean_cols(phones)\r\n",
    "phones = preproc.fill_empty_lists(phones)\r\n",
    "phones = preproc.preprocess_reviews(phones)\r\n",
    "phones = feature_eng.generate_features(phones)\r\n",
    "phones = feature_eng.do_PCA(phones)\r\n",
    "phones['TOTAL_SALES_QBINNED'] = pd.qcut(phones['TOTAL_SALES'], 3, labels=[0,1,2])\r\n",
    "# desktops\r\n",
    "desktops = pd.read_json('full_data/desktops.json')\r\n",
    "desktops = join_y(desktops, 'raw_data/desktops_sales.csv')\r\n",
    "desktops = preproc.clean_cols(desktops)\r\n",
    "desktops = preproc.fill_empty_lists(desktops)\r\n",
    "desktops = preproc.preprocess_reviews(desktops)\r\n",
    "desktops = feature_eng.generate_features(desktops)\r\n",
    "desktops = feature_eng.do_PCA(desktops)\r\n",
    "desktops['TOTAL_SALES_QBINNED'] = pd.qcut(desktops['TOTAL_SALES'], 3, labels=[0,1,2])\r\n",
    "# tablets\r\n",
    "tablets = pd.read_json('full_data/tablets.json')\r\n",
    "tablets = join_y(tablets, 'raw_data/tablet_sales.csv')\r\n",
    "tablets = tablets[tablets['no_reviews'].notna()]\r\n",
    "tablets = preproc.clean_cols(tablets)\r\n",
    "tablets = preproc.fill_empty_lists(tablets)\r\n",
    "tablets = preproc.preprocess_reviews(tablets)\r\n",
    "tablets = feature_eng.generate_features(tablets)\r\n",
    "tablets = feature_eng.do_PCA(tablets)\r\n",
    "tablets['TOTAL_SALES_QBINNED'] = pd.qcut(tablets['TOTAL_SALES'], 3, labels=[0,1,2])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scaling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "laptops = laptops.select_dtypes(include=['float', 'int64','int32','float64'])\r\n",
    "laptops['price/Rvol'] = laptops['price/Rvol'].replace(np.inf, laptops['price/Rvol'].median())\r\n",
    "for col in laptops.columns:\r\n",
    "    laptops[col] = laptops[col].replace(np.nan, laptops[col].median())\r\n",
    "laptops = (laptops-laptops.mean())/laptops.std()\r\n",
    "\r\n",
    "laptops = feature_eng.get_y_true(laptops)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "phones = phones.select_dtypes(include=['float', 'int64','int32','float64'])\r\n",
    "phones['price/Rvol'] = phones['price/Rvol'].replace(np.inf, phones['price/Rvol'].median())\r\n",
    "for col in phones.columns:\r\n",
    "    phones[col] = phones[col].replace(np.nan, phones[col].median())\r\n",
    "phones = (phones-phones.mean())/phones.std()\r\n",
    "\r\n",
    "phones = feature_eng.get_y_true(phones)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tablets = tablets.select_dtypes(include=['float', 'int64','int32','float64'])\r\n",
    "tablets['price/Rvol'] = tablets['price/Rvol'].replace(np.inf, tablets['price/Rvol'].median())\r\n",
    "for col in tablets.columns:\r\n",
    "    tablets[col] = tablets[col].replace(np.nan, tablets[col].median())\r\n",
    "tablets = (tablets-tablets.mean())/tablets.std()\r\n",
    "\r\n",
    "tablets = feature_eng.get_y_true(tablets)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "desktops = desktops.select_dtypes(include=['float', 'int64','int32','float64'])\r\n",
    "desktops['price/Rvol'] = desktops['price/Rvol'].replace(np.inf, desktops['price/Rvol'].median())\r\n",
    "for col in desktops.columns:\r\n",
    "    desktops[col] = desktops[col].replace(np.nan, desktops[col].median())\r\n",
    "desktops = (desktops-desktops.mean())/desktops.std()\r\n",
    "\r\n",
    "desktops = feature_eng.get_y_true(desktops)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TOP 3 features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "laptops.name = 'laptops'\r\n",
    "desktops.name = 'desktops'\r\n",
    "phones.name = 'phones'\r\n",
    "tablets.name = 'tablets'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "results = run_dbscan_gs(\r\n",
    "    dataframes=[laptops,phones,desktops,tablets],\r\n",
    "    features=['no_reviews','Rvol/%rec','pos_reviews'],\r\n",
    "    epsilon_range = [x / 100.0 for x in range(50, 100, 5)],\r\n",
    "    min_sample_range = [x for x in range(2, 6, 1)],\r\n",
    "    iterations=10\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "results"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "phones['y_true'].value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## laptops"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lX['Rvol/%rec'] = lX['Rvol/%rec'].replace(np.nan, lX['Rvol/%rec'].median())\r\n",
    "dbscan_model = DBSCAN(eps=0.8, min_samples=(len(lX))/4)\r\n",
    "db_clust = dbscan_model.fit_predict(lX[['no_reviews','Rvol/%rec','pos_reviews']])\r\n",
    "laptops['db_clust'] = pd.Series(db_clust, index=laptops.index)\r\n",
    "evaluate_clusters(laptops['db_clust'] ,laptops['TOTAL_SALES'],  laptops['TOTAL_SALES_QBINNED'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cluster_intelligence.cluster_report(lX[['no_reviews','Rvol/%rec','pos_reviews']],db_clust)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "get_eval_scores(laptops['y_true'], laptops['db_clust'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(laptops.loc[laptops.db_clust==-1]['TOTAL_SALES'].mean())\r\n",
    "print(laptops.loc[laptops.db_clust==-0]['TOTAL_SALES'].mean())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lX['db_clust'] = pd.Series(db_clust, index=lX.index)\r\n",
    "f, axes = plt.subplots(1,3, figsize=(15,15))\r\n",
    "sns.scatterplot(x=lX['no_reviews'], y=lX['pos_reviews'], hue=lX['db_clust'],ax=axes[0])\r\n",
    "sns.scatterplot(x=lX['no_reviews'], y=lX['Rvol/%rec'],hue=lX['db_clust'], ax=axes[1])\r\n",
    "sns.scatterplot(x=lX['pos_reviews'], y=lX['Rvol/%rec'],hue=lX['db_clust'], ax=axes[2])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.neighbors import NearestNeighbors\r\n",
    "neigh = NearestNeighbors(n_neighbors=2)\r\n",
    "nbrs = neigh.fit(lX[['no_reviews','Rvol/%rec','pos_reviews']])\r\n",
    "distances, indices = nbrs.kneighbors(lX[['no_reviews','Rvol/%rec','pos_reviews']])\r\n",
    "\r\n",
    "# Plotting K-distance Graph\r\n",
    "distances = np.sort(distances, axis=0)\r\n",
    "distances = distances[:,1]\r\n",
    "plt.figure(figsize=(20,10))\r\n",
    "plt.plot(distances)\r\n",
    "plt.title('K-distance Graph',fontsize=20)\r\n",
    "plt.xlabel('Data Points sorted by distance',fontsize=14)\r\n",
    "plt.ylabel('Epsilon',fontsize=14)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## phones"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pX['Rvol/%rec'] = pX['Rvol/%rec'].replace(np.nan, pX['Rvol/%rec'].median())\r\n",
    "dbscan_model = DBSCAN(eps=1, min_samples=(len(pX))/4)\r\n",
    "db_clust = dbscan_model.fit_predict(pX[['no_reviews','Rvol/%rec','pos_reviews']])\r\n",
    "phones['db_clust'] = pd.Series(db_clust, index=phones.index)\r\n",
    "evaluate_clusters(phones['db_clust'] ,phones['TOTAL_SALES'],  phones['TOTAL_SALES_QBINNED'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cluster_intelligence.cluster_report(pX[['no_reviews','Rvol/%rec','pos_reviews']],db_clust)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "get_eval_scores(phones['y_true'], phones['db_clust'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(phones.loc[phones.db_clust==-1]['TOTAL_SALES'].mean())\r\n",
    "print(phones.loc[phones.db_clust==-0]['TOTAL_SALES'].mean())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pX['db_clust'] = pd.Series(db_clust, index=pX.index)\r\n",
    "f, axes = plt.subplots(1,3, figsize=(15,15))\r\n",
    "sns.scatterplot(x=pX['no_reviews'], y=pX['pos_reviews'], hue=pX['db_clust'],ax=axes[0])\r\n",
    "sns.scatterplot(x=pX['no_reviews'], y=pX['Rvol/%rec'],hue=pX['db_clust'], ax=axes[1])\r\n",
    "sns.scatterplot(x=pX['pos_reviews'], y=pX['Rvol/%rec'],hue=pX['db_clust'], ax=axes[2])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## desktops"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dX['Rvol/%rec'] = dX['Rvol/%rec'].replace(np.nan, dX['Rvol/%rec'].median())\r\n",
    "dbscan_model = DBSCAN(eps=1, min_samples=(len(dX))/4)\r\n",
    "db_clust = dbscan_model.fit_predict(dX[['no_reviews','Rvol/%rec','pos_reviews']])\r\n",
    "desktops['db_clust'] = pd.Series(db_clust, index=desktops.index)\r\n",
    "evaluate_clusters(desktops['db_clust'] ,desktops['TOTAL_SALES'],  desktops['TOTAL_SALES_QBINNED'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cluster_intelligence.cluster_report(dX[['no_reviews','Rvol/%rec','pos_reviews']],db_clust)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "get_eval_scores(desktops['y_true'], desktops['db_clust'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(desktops.loc[desktops.db_clust==-1]['TOTAL_SALES'].mean())\r\n",
    "print(desktops.loc[desktops.db_clust==-0]['TOTAL_SALES'].mean())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dX['db_clust'] = pd.Series(db_clust, index=dX.index)\r\n",
    "f, axes = plt.subplots(1,3, figsize=(15,15))\r\n",
    "sns.scatterplot(x=dX['no_reviews'], y=dX['pos_reviews'], hue=dX['db_clust'],ax=axes[0])\r\n",
    "sns.scatterplot(x=dX['no_reviews'], y=dX['Rvol/%rec'],hue=dX['db_clust'], ax=axes[1])\r\n",
    "sns.scatterplot(x=dX['pos_reviews'], y=dX['Rvol/%rec'],hue=dX['db_clust'], ax=axes[2])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## tablets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tX['Rvol/%rec'] = tX['Rvol/%rec'].replace(np.nan, tX['Rvol/%rec'].median())\r\n",
    "dbscan_model = DBSCAN(eps=1, min_samples=(len(tX))/4)\r\n",
    "db_clust = dbscan_model.fit_predict(tX[['no_reviews','Rvol/%rec','pos_reviews']])\r\n",
    "tablets['db_clust'] = pd.Series(db_clust, index=tablets.index)\r\n",
    "evaluate_clusters(tablets['db_clust'] ,tablets['TOTAL_SALES'],  tablets['TOTAL_SALES_QBINNED'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cluster_intelligence.cluster_report(tX[['no_reviews','Rvol/%rec','pos_reviews']],db_clust)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "get_eval_scores(tablets['y_true'], tablets['db_clust'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(tablets.loc[tablets.db_clust==-1]['TOTAL_SALES'].mean())\r\n",
    "print(tablets.loc[tablets.db_clust==-0]['TOTAL_SALES'].mean())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tX['db_clust'] = pd.Series(db_clust, index=tX.index)\r\n",
    "f, axes = plt.subplots(1,3, figsize=(15,15))\r\n",
    "sns.scatterplot(x=tX['no_reviews'], y=tX['pos_reviews'], hue=tX['db_clust'],ax=axes[0])\r\n",
    "sns.scatterplot(x=tX['no_reviews'], y=tX['Rvol/%rec'],hue=tX['db_clust'], ax=axes[1])\r\n",
    "sns.scatterplot(x=tX['pos_reviews'], y=tX['Rvol/%rec'],hue=tX['db_clust'], ax=axes[2])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.0 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "interpreter": {
   "hash": "ee264c1354800df28a0473499e9bea074eb80c2a88ae16a4d8af7f553f7ba238"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}